# Article Summarizer Agent

**Resumo automÃ¡tico de artigos da web com bypass avanÃ§ado de WAF (Cloudflare, DataCamp, etc). 100% open-source, pronto para deploy gratuito.**

---

## âœ¨ DescriÃ§Ã£o

O Article Summarizer Agent Ã© uma aplicaÃ§Ã£o Python que extrai, processa e resume artigos de qualquer site, mesmo aqueles protegidos por WAFs avanÃ§ados (como Cloudflare). Utiliza tÃ©cnicas modernas de scraping, Selenium stealth, fallback automÃ¡tico e geraÃ§Ã£o de sumÃ¡rio em mÃºltiplos formatos (txt, md, json).

- **Bypass de WAF**: Headers avanÃ§ados, Selenium stealth, cloudscraper fallback
- **Resumo automÃ¡tico**: MÃ©todos extractive, generative e hÃ­brido
- **API RESTful** e interface web Flask
- **Pronto para deploy gratuito** (Render, Railway, Vercel, Deta, Codespaces)

---

## ğŸš€ InstalaÃ§Ã£o Local

```bash
git clone https://github.com/Lucasantunesribeiro/article_summarizer_agent.git
cd article_summarizer_agent
python -m venv .venv
source .venv/bin/activate  # ou .venv\Scripts\activate no Windows
pip install -r requirements.txt
```

---

## ğŸ–¥ï¸ Como Usar Localmente

```bash
python main.py --url "https://www.datacamp.com/pt/blog/top-open-source-llms"
```

Ou rode a interface web:

```bash
python start_app.py
# Acesse http://localhost:5000
```

---

## ğŸ§ª Testes

```bash
python test_datacamp_waf.py
python test_datacamp_selenium.py
python test_advanced_waf_bypass.py
```

---

## â˜ï¸ Deploy Gratuito

### Render.com
1. Crie um novo serviÃ§o Web Service (Python)
2. Configure o build command: `pip install -r requirements.txt`
3. Configure o start command: `python start_app.py`
4. Adicione variÃ¡veis de ambiente se necessÃ¡rio

### Railway.app
1. Novo projeto > Deploy from GitHub
2. Start command: `python start_app.py`

### Vercel (com Python API)
- Use o Vercel Python template e adapte o start para `start_app.py`

### GitHub Codespaces
- Basta abrir o Codespace e rodar `python start_app.py`

---

## ğŸ“¦ Estrutura de Pastas

```
article_summarizer_agent/
â”œâ”€â”€ app.py                # Interface web Flask
â”œâ”€â”€ main.py               # CLI principal
â”œâ”€â”€ modules/              # LÃ³gica de scraping, processamento, resumo
â”œâ”€â”€ outputs/              # SaÃ­das geradas (txt, md, json)
â”œâ”€â”€ requirements.txt      # DependÃªncias
â”œâ”€â”€ test_*.py             # Testes automatizados
â”œâ”€â”€ static/, templates/   # Frontend web
â”œâ”€â”€ .cache/               # Cache local
â””â”€â”€ ...
```

---

## ğŸ› ï¸ Principais DependÃªncias
- Flask
- Selenium, undetected-chromedriver, webdriver-manager
- cloudscraper, fake-useragent
- beautifulsoup4, requests, chardet
- scikit-learn, numpy, nltk
- transformers (opcional para resumo generativo)

---

## ğŸ”‘ CrÃ©ditos
- Desenvolvido por [Lucasantunesribeiro](https://github.com/Lucasantunesribeiro)
- InspiraÃ§Ã£o: projetos open-source de scraping e NLP

## ğŸ“„ LicenÃ§a
MIT License